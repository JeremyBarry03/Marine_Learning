{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGirH_42UDDo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.densenet121(num_classes=10)\n",
        "...\n",
        "model.classifier = nn.Linear(in_features, len(CLASS_NAMES))\n"
      ],
      "metadata": {
        "id": "Ixy2UFzBdBtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"../Marine_Learning\").resolve()\n",
        "IMAGE_DIR = PROJECT_ROOT / \"data\" / \"data\" / \"classification_dataset\" / \"images\"\n",
        "MANIFEST_PATH = PROJECT_ROOT / \"data\" / \"data\" / \"classification_dataset\" / \"labels.txt\"\n",
        "SPLIT_PATH = PROJECT_ROOT / \"models\" / \"splits.json\"\n",
        "\n",
        "CLASS_NAMES = [\"Scallop\", \"Roundfish\", \"Crab\", \"Whelk\", \"Skate\", \"Flatfish\", \"Eel\"]\n",
        "CLASS_TO_INDEX = {name.lower(): idx for idx, name in enumerate(CLASS_NAMES)}\n",
        "SEED = 415\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n"
      ],
      "metadata": {
        "id": "UvCD9w7hdYjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from typing import Dict, List, Sequence, Tuple\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "def _load_manifest(manifest_path: Path, image_dir: Path) -> List[Tuple[str, int]]:\n",
        "    if not manifest_path.exists():\n",
        "        raise FileNotFoundError(f\"Manifest missing at {manifest_path}\")\n",
        "    records: List[Tuple[str, int]] = []\n",
        "    with manifest_path.open(\"r\", encoding=\"utf-8\") as handle:\n",
        "        for line in handle:\n",
        "            stripped = line.strip()\n",
        "            if not stripped:\n",
        "                continue\n",
        "            filename, *label_parts = stripped.split()\n",
        "            label_key = \" \".join(label_parts).lower()\n",
        "            label_idx = CLASS_TO_INDEX[label_key]\n",
        "            image_path = image_dir / filename\n",
        "            if not image_path.exists():\n",
        "                raise FileNotFoundError(f\"Missing image: {image_path}\")\n",
        "            records.append((str(image_path), label_idx))\n",
        "    if not records:\n",
        "        raise ValueError(\"Manifest contained no usable records.\")\n",
        "    return records\n",
        "\n",
        "def _stratified_split(records: Sequence[Tuple[str, int]], train_ratio: float, val_ratio: float, seed: int):\n",
        "    grouped: Dict[int, List[Tuple[str, int]]] = {}\n",
        "    for path, label in records:\n",
        "        grouped.setdefault(label, []).append((path, label))\n",
        "\n",
        "    rng = random.Random(seed)\n",
        "    splits = {\"train\": ([], []), \"val\": ([], []), \"test\": ([], [])}\n",
        "\n",
        "    for label, items in grouped.items():\n",
        "        rng.shuffle(items)\n",
        "        total = len(items)\n",
        "        train_count = max(1, round(total * train_ratio))\n",
        "        val_count = max(1, round(total * val_ratio))\n",
        "        if train_count + val_count >= total:\n",
        "            val_count = max(1, total - train_count - 1)\n",
        "        train_items = items[:train_count]\n",
        "        val_items = items[train_count: train_count + val_count]\n",
        "        test_items = items[train_count + val_count:]\n",
        "\n",
        "        for split_name, subset in ((\"train\", train_items), (\"val\", val_items), (\"test\", test_items)):\n",
        "            paths, labels = splits[split_name]\n",
        "            for path, lbl in subset:\n",
        "                paths.append(path)\n",
        "                labels.append(lbl)\n",
        "\n",
        "    return splits\n",
        "\n",
        "def load_or_create_splits(split_path: Path):\n",
        "    records = _load_manifest(MANIFEST_PATH, IMAGE_DIR)\n",
        "    if split_path.exists():\n",
        "        with split_path.open(\"r\", encoding=\"utf-8\") as handle:\n",
        "            saved = json.load(handle)\n",
        "        filename_to_label = {Path(path).name: label for path, label in records}\n",
        "        splits = {}\n",
        "        for split_name, filenames in saved.items():\n",
        "            paths = [str(IMAGE_DIR / name) for name in filenames]\n",
        "            labels = [filename_to_label[Path(p).name] for p in paths]\n",
        "            splits[split_name] = (paths, labels)\n",
        "        return splits\n",
        "\n",
        "    splits = _stratified_split(records, TRAIN_RATIO, VAL_RATIO, SEED)\n",
        "    serializable = {name: [Path(path).name for path in paths] for name, (paths, _) in splits.items()}\n",
        "    split_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with split_path.open(\"w\", encoding=\"utf-8\") as handle:\n",
        "        json.dump(serializable, handle, indent=2)\n",
        "    return splits\n"
      ],
      "metadata": {
        "id": "21WRajdpdrke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BenthicDataset(Dataset):\n",
        "    def __init__(self, filepaths, labels, transform=None):\n",
        "        self.filepaths = list(filepaths)\n",
        "        self.labels = list(labels)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.filepaths[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "def build_transforms(image_size=224, random_erasing_p=0.5):\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(int(image_size * 1.2)),\n",
        "        transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.15, contrast=0.15,\n",
        "                               saturation=0.15, hue=0.05),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "        transforms.RandomErasing(p=random_erasing_p, scale=(0.02, 0.25),\n",
        "                                 ratio=(0.3, 3.3), value=\"random\"),\n",
        "    ])\n",
        "    eval_transform = transforms.Compose([\n",
        "        transforms.Resize(int(image_size * 1.1)),\n",
        "        transforms.CenterCrop(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "    return train_transform, eval_transform\n",
        "\n",
        "def build_dataloaders(splits, image_size, batch_size):\n",
        "    train_tfm, eval_tfm = build_transforms(image_size=image_size)\n",
        "    train_files, train_labels = splits[\"train\"]\n",
        "    val_files, val_labels = splits[\"val\"]\n",
        "    test_files, test_labels = splits[\"test\"]\n",
        "\n",
        "    train_ds = BenthicDataset(train_files, train_labels, train_tfm)\n",
        "    val_ds = BenthicDataset(val_files, val_labels, eval_tfm)\n",
        "    test_ds = BenthicDataset(test_files, test_labels, eval_tfm)\n",
        "\n",
        "    loader_kwargs = dict(batch_size=batch_size,\n",
        "                         num_workers=0,\n",
        "                         pin_memory=torch.cuda.is_available())\n",
        "    return (\n",
        "        DataLoader(train_ds, shuffle=True, **loader_kwargs),\n",
        "        DataLoader(val_ds, shuffle=False, **loader_kwargs),\n",
        "        DataLoader(test_ds, shuffle=False, **loader_kwargs),\n",
        "    )\n"
      ],
      "metadata": {
        "id": "gPAzy79_eDj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = load_or_create_splits(SPLIT_PATH)\n",
        "train_loader, val_loader, test_loader = build_dataloaders(\n",
        "    splits,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"Train samples: {len(train_loader.dataset)} | \"\n",
        "    f\"Val samples: {len(val_loader.dataset)} | \"\n",
        "    f\"Test samples: {len(test_loader.dataset)}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "BYD8Buf0ePX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_images, batch_labels = next(iter(train_loader))\n",
        "inv_norm = transforms.Normalize(\n",
        "    mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n",
        "    std=[1 / 0.229, 1 / 0.224, 1 / 0.225],\n",
        ")\n",
        "\n",
        "cols = 5\n",
        "rows = math.ceil(batch_images.size(0) / cols)\n",
        "plt.figure(figsize=(cols * 3, rows * 3))\n",
        "for idx in range(min(batch_images.size(0), cols * rows)):\n",
        "    img = inv_norm(batch_images[idx]).clamp(0, 1).permute(1, 2, 0).cpu().numpy()\n",
        "    label = CLASS_NAMES[batch_labels[idx]]\n",
        "    ax = plt.subplot(rows, cols, idx + 1)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(label)\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hxxdrBsoeTxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "REPO_ID = \"timm/densenet121.cifar10\"\n",
        "STATE_DICT_FILE = \"pytorch_model.bin\"\n",
        "\n",
        "state_dict_path = hf_hub_download(repo_id=REPO_ID, filename=STATE_DICT_FILE)\n",
        "state_dict = torch.load(state_dict_path, map_location=\"cpu\")\n",
        "\n",
        "model = models.densenet121(num_classes=10)\n",
        "missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
        "print(\"Missing keys:\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "in_features = model.classifier.in_features\n",
        "model.classifier = nn.Linear(in_features, len(CLASS_NAMES))\n",
        "nn.init.trunc_normal_(model.classifier.weight, mean=0.0, std=0.02)\n",
        "if model.classifier.bias is not None:\n",
        "    nn.init.zeros_(model.classifier.bias)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "KKdAwrRnekKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
        "plt.plot(history[\"val_acc\"], label=\"Val Acc\")\n",
        "plt.legend(); plt.title(\"Accuracy vs Epoch\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.legend(); plt.title(\"Loss vs Epoch\")\n"
      ],
      "metadata": {
        "id": "cAARsHkTfPkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = classification_report(\n",
        "    test_targets.numpy(),\n",
        "    test_preds.numpy(),\n",
        "    target_names=CLASS_NAMES,\n",
        "    output_dict=True,\n",
        ")\n",
        "\n",
        "focus = {cls: targets[cls] for cls in (\"Crab\", \"Eel\")}\n",
        "print(json.dumps(focus, indent=2))\n"
      ],
      "metadata": {
        "id": "LrHuUW5PfjGf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}